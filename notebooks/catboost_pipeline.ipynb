{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from pycaret.classification import *\n",
    "from metrics import compute_single_col_score, get_tresholds\n",
    "from helper import make_prediction\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import catboost.datasets as cbd\n",
    "import catboost.utils as cbu\n",
    "import hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(cfg.PREPARED_TRAIN_DATA_PATH)\n",
    "test = pd.read_pickle(cfg.PREPARED_TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cat_col_pairs():\n",
    "    n = len(cfg.CAT_UNORDERED_COLS)\n",
    "    for i in range(n):\n",
    "        c1 = cfg.CAT_UNORDERED_COLS[i]\n",
    "        for j in range(i+1, n):\n",
    "            c2 = cfg.CAT_UNORDERED_COLS[j]\n",
    "            yield c1, c2, f'{c1}_{c2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_paired_categories(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    for c1, c2, paired_col in generate_cat_col_pairs():\n",
    "        data[paired_col] = data[c1].astype('str') + ' | ' + data[c2].astype('str')\n",
    "        data[paired_col] = data[paired_col].astype('category')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = add_paired_categories(train)\n",
    "# test = add_paired_categories(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BI_UNORDERED_CAT_COLS = [paired_col for c1, c2, paired_col in generate_cat_col_pairs()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train.drop(cfg.TARGETS, axis=1), train[cfg.TARGETS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_oof = pd.DataFrame(data=np.zeros(shape=(len(train), len(cfg.TARGETS))), index=train.index, columns=cfg.TARGETS)\n",
    "pred_proba_test = pd.DataFrame(data=np.zeros(shape=(len(test), len(cfg.TARGETS))), index=test.index, columns=cfg.TARGETS)\n",
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_FAMILY_NAME = 'catboost'\n",
    "EXPERIMENT_NAME = 'baseline'\n",
    "RANDOM_STATE = 77\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    }
   ],
   "source": [
    "cv = MultilabelStratifiedKFold(n_splits=N_SPLITS, random_state=RANDOM_STATE, shuffle=True)\n",
    "\n",
    "test_pool = cb.Pool(\n",
    "        data=test,\n",
    "        cat_features=cfg.CAT_UNORDERED_COLS)\n",
    "\n",
    "fold = 0\n",
    "for train_idx, val_idx in cv.split(X_train, Y_train):\n",
    "\n",
    "    train_pool = cb.Pool(\n",
    "        data=X_train.iloc[train_idx], \n",
    "        label=Y_train.iloc[train_idx],\n",
    "        cat_features=cfg.CAT_UNORDERED_COLS)\n",
    "\n",
    "    val_pool = cb.Pool(\n",
    "        data=X_train.iloc[val_idx], \n",
    "        label=Y_train.iloc[val_idx],\n",
    "        cat_features=cfg.CAT_UNORDERED_COLS)\n",
    "\n",
    "    clf = cb.CatBoostClassifier(\n",
    "        loss_function='MultiLogloss',\n",
    "        custom_metric=['Recall', 'F1'],\n",
    "        iterations=1000,\n",
    "        silent=True,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=2.0,\n",
    "        learning_rate=0.01,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "\n",
    "    clf.fit(train_pool, eval_set=val_pool, metric_period=10, plot=False)\n",
    "    \n",
    "    model_path = os.path.join(cfg.MODELS_PATH, EXPERIMENT_FAMILY_NAME, EXPERIMENT_NAME, f'{EXPERIMENT_NAME}_fold_{fold}.cbm')\n",
    "    clf.save_model(model_path)\n",
    "    \n",
    "    pred_proba_oof.iloc[val_idx, :] = clf.predict_proba(val_pool)\n",
    "    pred_proba_test.iloc[:, :] += clf.predict_proba(test_pool)\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "pred_proba_test /= N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6855817004516904\n"
     ]
    }
   ],
   "source": [
    "tresholds = get_tresholds(train[cfg.TARGETS], pred_proba_oof)\n",
    "sample_submission = pd.read_csv(cfg.SAMPLE_SUBMISSION_PATH).set_index('ID')\n",
    "submission = make_prediction(pred_proba_test, tresholds, sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6855817004516904 - without generated cat features\n",
    "\n",
    "# iterations=1000,\n",
    "# silent=True,\n",
    "# depth=6,\n",
    "# l2_leaf_reg=2.0,\n",
    "# learning_rate=0.01,\n",
    "# early_stopping_rounds=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'{EXPERIMENT_NAME}.csv'\n",
    "submission.to_csv(os.path.join(cfg.SUBMISSION_PATH, EXPERIMENT_FAMILY_NAME, name))\n",
    "pred_proba_oof.to_pickle(os.path.join(cfg.OOF_PRED_PATH, EXPERIMENT_FAMILY_NAME, name))\n",
    "pred_proba_test.to_pickle(os.path.join(cfg.TEST_PRED_PATH, EXPERIMENT_FAMILY_NAME, name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
